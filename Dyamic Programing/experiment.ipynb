{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import policy_evaluation, policy_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5\n",
    "n_states = n_rows*n_cols\n",
    "n_actions = 4\n",
    "n_rewards = 1\n",
    "\n",
    "actions = {\n",
    "    \"up\" : 0,\n",
    "    \"right\" : 1,\n",
    "    \"down\" : 2,\n",
    "    \"left\": 3,\n",
    "}\n",
    "\n",
    "coord_A = (1, 0)\n",
    "coord_B = (3, 0)\n",
    "coord_new_A = (1, 4)\n",
    "coord_new_B = (3, 2)\n",
    "reward_A = 10\n",
    "reward_B = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.zeros((n_states, n_actions), dtype=np.float64)\n",
    "probabilities = np.zeros((n_states, n_actions, n_states, n_rewards ), dtype=np.float64)\n",
    "rewards  = np.zeros((n_states, n_actions, n_states, n_rewards ), dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(n_states):\n",
    "    for a in range(n_actions):\n",
    "        policy[s, a] = 1/n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(n_states):\n",
    "    coord_x = s%n_cols\n",
    "    coord_y = s//n_cols\n",
    "    if (coord_x == coord_A[0] and coord_y == coord_A[1]):\n",
    "        new_state = coord_new_A[0] + coord_new_A[1]*n_cols\n",
    "        probabilities[s, actions[\"up\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"down\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"right\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"left\"], new_state, 0] = 1\n",
    "        rewards[s, actions[\"up\"], new_state, 0] = reward_A\n",
    "        rewards[s, actions[\"down\"], new_state, 0] = reward_A\n",
    "        rewards[s, actions[\"right\"], new_state, 0] = reward_A\n",
    "        rewards[s, actions[\"left\"], new_state, 0] = reward_A    \n",
    "        continue\n",
    "    if (coord_x == coord_B[0] and coord_y == coord_B[1]):\n",
    "        new_state = coord_new_B[0] + coord_new_B[1]*n_cols\n",
    "        probabilities[s, actions[\"up\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"down\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"right\"], new_state, 0] = 1\n",
    "        probabilities[s, actions[\"left\"], new_state, 0] = 1\n",
    "        rewards[s, actions[\"up\"], new_state, 0] = reward_B\n",
    "        rewards[s, actions[\"down\"], new_state, 0] = reward_B\n",
    "        rewards[s, actions[\"right\"], new_state, 0] = reward_B\n",
    "        rewards[s, actions[\"left\"], new_state, 0] = reward_B    \n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if coord_y == 0:\n",
    "        probabilities[s, actions[\"up\"], s, 0] = 1\n",
    "        rewards[s, actions[\"up\"], s, 0] = -1\n",
    "    else:\n",
    "        probabilities[s, actions[\"up\"], s - n_cols, 0] = 1\n",
    "    if coord_y == n_rows - 1:\n",
    "        probabilities[s, actions[\"down\"], s, 0] = 1\n",
    "        rewards[s, actions[\"down\"], s, 0] = -1\n",
    "    else:\n",
    "        probabilities[s, actions[\"down\"], s + n_cols, 0] = 1\n",
    "    if coord_x == 0:\n",
    "        probabilities[s, actions[\"left\"], s, 0] = 1\n",
    "        rewards[s, actions[\"left\"], s, 0] = -1\n",
    "    else:\n",
    "        probabilities[s, actions[\"left\"], s - 1, 0] = 1\n",
    "    if coord_x == n_cols - 1:\n",
    "        probabilities[s, actions[\"right\"], s, 0] = 1\n",
    "        rewards[s, actions[\"right\"], s, 0] = -1\n",
    "    else:\n",
    "        probabilities[s, actions[\"right\"], s + 1, 0] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.884328397808397e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.32246819,  8.80004103,  4.43804072,  5.33189108,  1.50216683],\n",
       "       [ 1.53400412,  3.0029234 ,  2.25986587,  1.91673862,  0.55649704],\n",
       "       [ 0.06269972,  0.74846428,  0.6824622 ,  0.36700499, -0.39451718],\n",
       "       [-0.96200041, -0.42542022, -0.34575067, -0.5770051 , -1.17469956],\n",
       "       [-1.84623149, -1.33525852, -1.2202336 , -1.41441724, -1.96690954]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = policy_evaluation(policy, probabilities, rewards, gamma=0.9)\n",
    "result.reshape((n_rows, n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.884328397808397e-05\n",
      "7.522660022838705e-05\n",
      "9.325635617514557e-05\n",
      "9.002809356664833e-05\n",
      "9.002809356664833e-05\n"
     ]
    }
   ],
   "source": [
    "optimal_values = policy_iteration(probabilities, rewards, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_values.reshape(n_rows, n_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7730ca559ff8feee379a2381e28d3e6f0cb3410e772809d377ff1828e961366a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
